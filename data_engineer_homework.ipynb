{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bridal-pottery",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "capital-guide",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set option to display all columns\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "incorporated-arnold",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>value</th>\n",
       "      <th>field</th>\n",
       "      <th>robot_id</th>\n",
       "      <th>run_uuid</th>\n",
       "      <th>sensor_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-11-23T20:40:00.005Z</td>\n",
       "      <td>821.780800</td>\n",
       "      <td>x</td>\n",
       "      <td>1</td>\n",
       "      <td>8.910096e+18</td>\n",
       "      <td>encoder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-11-23T20:40:00.017Z</td>\n",
       "      <td>821.821700</td>\n",
       "      <td>x</td>\n",
       "      <td>1</td>\n",
       "      <td>8.910096e+18</td>\n",
       "      <td>encoder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-11-23T20:40:00.029Z</td>\n",
       "      <td>821.850700</td>\n",
       "      <td>x</td>\n",
       "      <td>1</td>\n",
       "      <td>8.910096e+18</td>\n",
       "      <td>encoder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-11-23T20:40:00.041Z</td>\n",
       "      <td>821.896400</td>\n",
       "      <td>x</td>\n",
       "      <td>1</td>\n",
       "      <td>8.910096e+18</td>\n",
       "      <td>encoder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-11-23T20:40:00.053Z</td>\n",
       "      <td>821.957300</td>\n",
       "      <td>x</td>\n",
       "      <td>1</td>\n",
       "      <td>8.910096e+18</td>\n",
       "      <td>encoder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1546586</th>\n",
       "      <td>2022-11-23T20:41:17.59Z</td>\n",
       "      <td>-85.692373</td>\n",
       "      <td>fx</td>\n",
       "      <td>1</td>\n",
       "      <td>1.240519e+19</td>\n",
       "      <td>load_cell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1546587</th>\n",
       "      <td>2022-11-23T20:41:17.6Z</td>\n",
       "      <td>-87.231436</td>\n",
       "      <td>fx</td>\n",
       "      <td>1</td>\n",
       "      <td>1.240519e+19</td>\n",
       "      <td>load_cell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1546588</th>\n",
       "      <td>2022-11-23T20:41:17.61Z</td>\n",
       "      <td>-85.649405</td>\n",
       "      <td>fx</td>\n",
       "      <td>1</td>\n",
       "      <td>1.240519e+19</td>\n",
       "      <td>load_cell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1546589</th>\n",
       "      <td>2022-11-23T20:41:17.62Z</td>\n",
       "      <td>-86.430655</td>\n",
       "      <td>fx</td>\n",
       "      <td>1</td>\n",
       "      <td>1.240519e+19</td>\n",
       "      <td>load_cell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1546590</th>\n",
       "      <td>2022-11-23T20:41:17.63Z</td>\n",
       "      <td>-86.477530</td>\n",
       "      <td>fx</td>\n",
       "      <td>1</td>\n",
       "      <td>1.240519e+19</td>\n",
       "      <td>load_cell</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1546591 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             time       value field  robot_id      run_uuid  \\\n",
       "0        2022-11-23T20:40:00.005Z  821.780800     x         1  8.910096e+18   \n",
       "1        2022-11-23T20:40:00.017Z  821.821700     x         1  8.910096e+18   \n",
       "2        2022-11-23T20:40:00.029Z  821.850700     x         1  8.910096e+18   \n",
       "3        2022-11-23T20:40:00.041Z  821.896400     x         1  8.910096e+18   \n",
       "4        2022-11-23T20:40:00.053Z  821.957300     x         1  8.910096e+18   \n",
       "...                           ...         ...   ...       ...           ...   \n",
       "1546586   2022-11-23T20:41:17.59Z  -85.692373    fx         1  1.240519e+19   \n",
       "1546587    2022-11-23T20:41:17.6Z  -87.231436    fx         1  1.240519e+19   \n",
       "1546588   2022-11-23T20:41:17.61Z  -85.649405    fx         1  1.240519e+19   \n",
       "1546589   2022-11-23T20:41:17.62Z  -86.430655    fx         1  1.240519e+19   \n",
       "1546590   2022-11-23T20:41:17.63Z  -86.477530    fx         1  1.240519e+19   \n",
       "\n",
       "        sensor_type  \n",
       "0           encoder  \n",
       "1           encoder  \n",
       "2           encoder  \n",
       "3           encoder  \n",
       "4           encoder  \n",
       "...             ...  \n",
       "1546586   load_cell  \n",
       "1546587   load_cell  \n",
       "1546588   load_cell  \n",
       "1546589   load_cell  \n",
       "1546590   load_cell  \n",
       "\n",
       "[1546591 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet('data/sample.parquet')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "congressional-macintosh",
   "metadata": {},
   "source": [
    "## Sort the rows based on the time to make sure that the rows are stored sequentialy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "deadly-police",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>value</th>\n",
       "      <th>field</th>\n",
       "      <th>robot_id</th>\n",
       "      <th>run_uuid</th>\n",
       "      <th>sensor_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>878828</th>\n",
       "      <td>2022-11-23T20:40:00.001Z</td>\n",
       "      <td>716.528276</td>\n",
       "      <td>fy</td>\n",
       "      <td>1</td>\n",
       "      <td>7.582293e+18</td>\n",
       "      <td>load_cell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938829</th>\n",
       "      <td>2022-11-23T20:40:00.001Z</td>\n",
       "      <td>-1547.340972</td>\n",
       "      <td>fz</td>\n",
       "      <td>1</td>\n",
       "      <td>7.582293e+18</td>\n",
       "      <td>load_cell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818827</th>\n",
       "      <td>2022-11-23T20:40:00.001Z</td>\n",
       "      <td>-1192.046953</td>\n",
       "      <td>fx</td>\n",
       "      <td>1</td>\n",
       "      <td>7.582293e+18</td>\n",
       "      <td>load_cell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118830</th>\n",
       "      <td>2022-11-23T20:40:00.003Z</td>\n",
       "      <td>84.484822</td>\n",
       "      <td>fz</td>\n",
       "      <td>2</td>\n",
       "      <td>7.582293e+18</td>\n",
       "      <td>load_cell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058830</th>\n",
       "      <td>2022-11-23T20:40:00.003Z</td>\n",
       "      <td>489.207227</td>\n",
       "      <td>fy</td>\n",
       "      <td>2</td>\n",
       "      <td>7.582293e+18</td>\n",
       "      <td>load_cell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550011</th>\n",
       "      <td>2022-11-23T20:49:59.9Z</td>\n",
       "      <td>1000.769000</td>\n",
       "      <td>y</td>\n",
       "      <td>2</td>\n",
       "      <td>7.582293e+18</td>\n",
       "      <td>encoder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600012</th>\n",
       "      <td>2022-11-23T20:49:59.9Z</td>\n",
       "      <td>-771.632000</td>\n",
       "      <td>z</td>\n",
       "      <td>2</td>\n",
       "      <td>7.582293e+18</td>\n",
       "      <td>encoder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549936</th>\n",
       "      <td>2022-11-23T20:49:59Z</td>\n",
       "      <td>1000.769000</td>\n",
       "      <td>y</td>\n",
       "      <td>2</td>\n",
       "      <td>7.582293e+18</td>\n",
       "      <td>encoder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599937</th>\n",
       "      <td>2022-11-23T20:49:59Z</td>\n",
       "      <td>-771.632000</td>\n",
       "      <td>z</td>\n",
       "      <td>2</td>\n",
       "      <td>7.582293e+18</td>\n",
       "      <td>encoder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499935</th>\n",
       "      <td>2022-11-23T20:49:59Z</td>\n",
       "      <td>3050.773000</td>\n",
       "      <td>x</td>\n",
       "      <td>2</td>\n",
       "      <td>7.582293e+18</td>\n",
       "      <td>encoder</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1546591 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             time        value field  robot_id      run_uuid  \\\n",
       "878828   2022-11-23T20:40:00.001Z   716.528276    fy         1  7.582293e+18   \n",
       "938829   2022-11-23T20:40:00.001Z -1547.340972    fz         1  7.582293e+18   \n",
       "818827   2022-11-23T20:40:00.001Z -1192.046953    fx         1  7.582293e+18   \n",
       "1118830  2022-11-23T20:40:00.003Z    84.484822    fz         2  7.582293e+18   \n",
       "1058830  2022-11-23T20:40:00.003Z   489.207227    fy         2  7.582293e+18   \n",
       "...                           ...          ...   ...       ...           ...   \n",
       "550011     2022-11-23T20:49:59.9Z  1000.769000     y         2  7.582293e+18   \n",
       "600012     2022-11-23T20:49:59.9Z  -771.632000     z         2  7.582293e+18   \n",
       "549936       2022-11-23T20:49:59Z  1000.769000     y         2  7.582293e+18   \n",
       "599937       2022-11-23T20:49:59Z  -771.632000     z         2  7.582293e+18   \n",
       "499935       2022-11-23T20:49:59Z  3050.773000     x         2  7.582293e+18   \n",
       "\n",
       "        sensor_type  \n",
       "878828    load_cell  \n",
       "938829    load_cell  \n",
       "818827    load_cell  \n",
       "1118830   load_cell  \n",
       "1058830   load_cell  \n",
       "...             ...  \n",
       "550011      encoder  \n",
       "600012      encoder  \n",
       "549936      encoder  \n",
       "599937      encoder  \n",
       "499935      encoder  \n",
       "\n",
       "[1546591 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sort_values('time')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satellite-lightweight",
   "metadata": {},
   "source": [
    "# 2.1 Preprocess and Clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "photographic-placement",
   "metadata": {},
   "source": [
    "## A method to check the data type of each column. If all column types are as expected this method pass otherwise it shows the columns with a mismatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "deluxe-dover",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_data_types(df, expected_types):\n",
    "    \"\"\"\n",
    "    Check if the DataFrame's columns have the expected data types.\n",
    "\n",
    "    :param df: pandas DataFrame to check\n",
    "    :param expected_types: Dictionary of expected data types {column_name: expected_type}\n",
    "    :return: None if types match, otherwise raises ValueError with mismatch details\n",
    "    \"\"\"\n",
    "    for column, expected_type in expected_types.items():\n",
    "        if column in df.columns:\n",
    "            if not pd.api.types.is_dtype_equal(df[column].dtype, expected_type):\n",
    "                raise ValueError(f\"Data type mismatch in column '{column}'. Expected {expected_type}, found {df[column].dtype}\")\n",
    "        else:\n",
    "            raise ValueError(f\"Column '{column}' not found in DataFrame\")\n",
    "    print(\"All column data types are as expected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "municipal-priority",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All column data types are as expected.\n"
     ]
    }
   ],
   "source": [
    "# Define the expected types\n",
    "expected_types = {\n",
    "    'time': 'object',\n",
    "    'value': 'float64',\n",
    "    'field': 'object',\n",
    "    'robot_id': 'int64',\n",
    "    'run_uuid': 'float64',\n",
    "    'sensor_type': 'object'\n",
    "}\n",
    "\n",
    "# Check data types\n",
    "check_data_types(df, expected_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handy-fifth",
   "metadata": {},
   "source": [
    "# 2.2 Convert timeseries to a wide format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "similar-surge",
   "metadata": {},
   "source": [
    "## Here, I split the data based on each part (run_uuid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "tired-productivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify Unique run_uuid Values\n",
    "unique_run_uuids = df['run_uuid'].unique()\n",
    "\n",
    "# Split the DataFrame\n",
    "dfs = {}\n",
    "for run_uuid in unique_run_uuids:\n",
    "    # Create a separate DataFrame for each run_uuid\n",
    "    dfs[run_uuid] = df[df['run_uuid'] == run_uuid]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tutorial-america",
   "metadata": {},
   "source": [
    "## For each part, I concatenated the field an robot_id and then used pivot to have them in one row and convert them to a wide format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "blank-introduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "for run_uuid, temp_df in dfs.items():\n",
    "    # Explicitly create a copy of the DataFrame slice\n",
    "    temp_df = temp_df.copy()\n",
    "\n",
    "    # Combine 'field' and 'robot_id'\n",
    "    temp_df['field_robot'] = temp_df['field'] + '_' + temp_df['robot_id'].astype(str)\n",
    "\n",
    "    # Pivot the DataFrame\n",
    "    pivot_df = temp_df.pivot_table(index='time', columns='field_robot', values='value', aggfunc='first')\n",
    "    \n",
    "    # Replace the original DataFrame in the dictionary with the pivoted one\n",
    "    dfs[run_uuid] = pivot_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaged-lewis",
   "metadata": {},
   "source": [
    "## Here for each part, there is one dataframe. They have all possible columns, but for some of the columns there is no data. So I keep the columns and add '0' for such columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "stylish-loading",
   "metadata": {},
   "outputs": [],
   "source": [
    "required_columns = ['fx_1', 'fx_2', 'fy_1', 'fy_2', 'fz_1', 'fz_2', 'x_1', 'x_2', 'y_1', 'y_2', 'z_1', 'z_2']\n",
    "\n",
    "for run_uuid, df in dfs.items():\n",
    "    # Identify missing columns\n",
    "    missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "\n",
    "    # Add missing columns with default value of 0\n",
    "    for col in missing_columns:\n",
    "        df[col] = 0\n",
    "\n",
    "    # Optionally, reorder columns to match the order in required_columns\n",
    "    df = df.reindex(columns=required_columns)\n",
    "\n",
    "    # Update the DataFrame in the dictionary\n",
    "    dfs[run_uuid] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "white-implementation",
   "metadata": {},
   "source": [
    "## After converting the timeseries to individual features, there are many gaps in the data. So the dataframe has null values. I used interpolation to fill the null values. Since the data is a time series and there is some form of continutiy, interpolation could be used here. It estimated the null values using existing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "super-villa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for run_uuid, df in dfs.items():\n",
    "    # Interpolate to fill missing values\n",
    "    df_interpolated = df.interpolate()\n",
    "\n",
    "    # Forward fill or backward fill to handle remaining missing values\n",
    "    df_filled = df_interpolated.fillna(method='bfill')\n",
    "\n",
    "    # Update the DataFrame in the dictionary\n",
    "    dfs[run_uuid] = df_filled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quantitative-procedure",
   "metadata": {},
   "source": [
    "# 2.3 Include Engineered/Calculated Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "necessary-deficit",
   "metadata": {},
   "source": [
    "## The velocity, acceleration, total velocity, total acceleration and total force values are calculated here. I used the current position of the robot, the previous position and the time difference between them to calcualte teh velocity. The way that the velocity and acceleration might need modifications but the logic works fine here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "active-vocabulary",
   "metadata": {},
   "outputs": [],
   "source": [
    "for run_uuid, df in dfs.items():\n",
    "    # Ensure the index is a datetime index\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "\n",
    "    # Calculate the time differences in seconds\n",
    "    df['time_diff'] = df.index.to_series().diff().dt.total_seconds()\n",
    "\n",
    "    # Calculate velocities\n",
    "    for axis in ['x', 'y', 'z']:\n",
    "        for robot_id in [1, 2]:\n",
    "            pos_col = f'{axis}_{robot_id}'\n",
    "            vel_col = f'v{axis}_{robot_id}'\n",
    "            df[vel_col] = df[pos_col].diff() / df['time_diff']\n",
    "\n",
    "    # Calculate accelerations\n",
    "    for axis in ['x', 'y', 'z']:\n",
    "        for robot_id in [1, 2]:\n",
    "            vel_col = f'v{axis}_{robot_id}'\n",
    "            acc_col = f'a{axis}_{robot_id}'\n",
    "            df[acc_col] = df[vel_col].diff() / df['time_diff']\n",
    "\n",
    "    # Calculate total velocities and accelerations\n",
    "    for robot_id in [1, 2]:\n",
    "        df[f'v{robot_id}'] = (df[f'vx_{robot_id}']**2 + df[f'vy_{robot_id}']**2 + df[f'vz_{robot_id}']**2)**0.5\n",
    "        df[f'a{robot_id}'] = (df[f'ax_{robot_id}']**2 + df[f'ay_{robot_id}']**2 + df[f'az_{robot_id}']**2)**0.5\n",
    "\n",
    "    # Calculate total forces\n",
    "    for robot_id in [1, 2]:\n",
    "        df[f'f{robot_id}'] = abs(df[f'fx_{robot_id}']) + abs(df[f'fy_{robot_id}']) + abs(df[f'fz_{robot_id}'])\n",
    "\n",
    "    # Update the DataFrame in the dictionary\n",
    "    dfs[run_uuid] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mineral-reliance",
   "metadata": {},
   "source": [
    "# 2.4 Calculate Runtime Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electrical-oxford",
   "metadata": {},
   "source": [
    "## Runtime Statistics is produced for each part and stored in a pandas dataframe. This dataframe is then saved in an csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "connected-peter",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_list = []\n",
    "\n",
    "for run_uuid, df in dfs.items():\n",
    "    # Ensure the index is a datetime index\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "\n",
    "    # Start and stop times\n",
    "    start_time = df.index[0]\n",
    "    stop_time = df.index[-1]\n",
    "\n",
    "    # Total runtime\n",
    "    total_runtime = stop_time - start_time\n",
    "\n",
    "    # Initialize total distance for each robot\n",
    "    total_distance = {1: 0, 2: 0}\n",
    "\n",
    "    # Calculate total distance traveled for each robot\n",
    "    for robot_id in [1, 2]:\n",
    "        # Calculate differences in x, y, z coordinates\n",
    "        dx = df[f'x_{robot_id}'].diff().fillna(0)\n",
    "        dy = df[f'y_{robot_id}'].diff().fillna(0)\n",
    "        dz = df[f'z_{robot_id}'].diff().fillna(0)\n",
    "\n",
    "        # Calculate distance for each step and sum\n",
    "        total_distance[robot_id] = np.sqrt(dx**2 + dy**2 + dz**2).sum()\n",
    "\n",
    "    # Create a dictionary of the results and add it to the list\n",
    "    results_dict = {\n",
    "        'run_uuid': run_uuid,\n",
    "        'start_time': start_time,\n",
    "        'stop_time': stop_time,\n",
    "        'total_runtime': total_runtime,\n",
    "        'total_distance_1': total_distance[1],\n",
    "        'total_distance_2': total_distance[2]\n",
    "    }\n",
    "    results_list.append(results_dict)\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "results_df = pd.DataFrame(results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "current-impact",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file name for the CSV file\n",
    "csv_file_name = 'results.csv'\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "results_df.to_csv(csv_file_name, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
